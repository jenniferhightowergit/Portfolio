{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23fcde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 10:54:13.717089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Cardiac.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 148\u001b[0m\n\u001b[1;32m    143\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.float_format\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m x) \u001b[38;5;66;03m# To supress numerical display in scientific notations\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;66;03m#library contains a number of probibility distributions and statistical functions\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCardiac.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#Quick Basic Checks\u001b[39;00m\n\u001b[1;32m    154\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cardiac.csv'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd #library for data manipulation and analysis\n",
    "import numpy as np #library used for working with arrays\n",
    "import matplotlib.pyplot as plt #library for plots and visualizations\n",
    "import seaborn as sns #library for visualizations\n",
    "from scipy.stats import norm #using normal distibutions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split # Sklearn package's randomized data splitting function\n",
    "\n",
    "#DEsision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "#Random Forest\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#To install xgboost library use - !pip install xgboost \n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# Libraries to split data, impute missing values \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Libraries to import decision tree classifier and different ensemble classifiers\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Libtune to tune model, get different metric scores\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# to create k folds of data and get cross validation score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import Linear Regression machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "###Heirarchical CLustering and PCA\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from scipy.cluster.hierarchy import cophenet, dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist  #Pairwise distribution between data points\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "\n",
    "#Deeplearning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "# Use a white background for matplotlib figures\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Neural Networks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,BatchNormalization\n",
    "\n",
    "import random\n",
    "from tensorflow.keras import backend\n",
    "random.seed(1)\n",
    "np.random.seed(1) \n",
    "tf.random.set_seed(1)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # To supress numerical display in scientific notations\n",
    "\n",
    "\n",
    "import scipy.stats #library contains a number of probibility distributions and statistical functions\n",
    "\n",
    "df = pd.read_csv('Cardiac.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Quick Basic Checks\n",
    "df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.describe(include='all').T\n",
    "\n",
    "#describe with condition\n",
    "df[(df.Listing_Price == 0)].describe()\n",
    "\n",
    "# hp is missing cause it does not seem to be reqcognized as a numerical column!\n",
    "cData.dtypes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of unique values in each column\n",
    "df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## clean data\n",
    "\n",
    "#upper case\n",
    "daw = df[(df['publisher'].str.contains('DAW', na=False)) & (df['average_rating']> 4)]\n",
    "daw['author'].unique()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "########rename columns\n",
    "\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'old_column': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Rename the column\n",
    "df = df.rename(columns={'old_column': 'new_column'})\n",
    "\n",
    "# Now, the column is renamed\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################CHECK NULLS and missing values\n",
    "\n",
    "\n",
    "df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#Lets see the count and the percentage of missing values in each column\n",
    "# selecting the instances where missing value is greater than 0\n",
    "pd.DataFrame({'Count':df.isnull().sum()[df.isnull().sum()>0],'Percentage':(df.isnull().sum()[df.isnull().sum()>0]/df.shape[0])*100})\n",
    "\n",
    "\n",
    "# replace the missing values with median value.\n",
    "# Note, we do not need to specify the column names below\n",
    "# every column's missing value is replaced with that column's median respectively  (axis =0 means columnwise)\n",
    "#cData = cData.fillna(cData.median())\n",
    "medianFiller = lambda x: x.fillna(x.median())\n",
    "cData = cData.apply(medianFiller,axis=0)\n",
    "\n",
    "\n",
    "#replace the listing price with the corresponding sale price for those observations\n",
    "df.loc[(df.Listing_Price == 0), [\"Listing_Price\"]] = df.loc[\n",
    "    (df.Listing_Price == 0), [\"Sale_Price\"]\n",
    "].values\n",
    "\n",
    "\n",
    "print(\"Age: \", \"Mean: \", df['Age'].mean(), \"Median: \", df['Age'].median(), \"Mode: \", df['Age'].mode())\n",
    "\n",
    "\n",
    "##making a new dataframe and droping a column\n",
    "data = df.drop(['Product'], axis=1)\n",
    "\n",
    "df.drop(['Product'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#options for dealing with nulls\n",
    "#1. replace with mean \n",
    "df['B'] = df['B'].fillna(df['B'].mean())\n",
    "\n",
    "\n",
    "#2 replace with median\n",
    "df['B'] = df['B'].fillna(df['B'].median())\n",
    "\n",
    "\n",
    "# Drop the last column from the DataFrame\n",
    "techSuppAttr = df.iloc[:, :-1]\n",
    "\n",
    "# Drop the first column from the DataFrame\n",
    "techSuppAttr = df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "#3 drop the rows where values is null\n",
    "# drop rows with null values\n",
    "df = df.dropna()\n",
    "# drop columns with null values\n",
    "df = df.dropna(axis=1)\n",
    "# drop rows that have all null values\n",
    "df = df.dropna(how='all')\n",
    "# drop rows where column B has null values\n",
    "df = df.dropna(subset=['B'])\n",
    "\n",
    "#It looks like wherever Bedroom is null the data points in other columns are also missing. \n",
    "#Let's check this.\n",
    "data.loc[data['Bedroom'].isnull()==True,'Bathroom'].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "# imputing missing values in Bedroom column\n",
    "data['Bedroom'] = data['Bedroom'].fillna(value = data.groupby(['Regionname','Type'])['Bedroom'].transform('mean'))\n",
    "\n",
    "# imputing missing values in Car column\n",
    "data['Car'] = data['Car'].fillna(value = data.groupby(['Regionname','Type'])['Car'].transform('mean'))\n",
    "\n",
    "# checking if all the missing values were imputed in Bedroom, Bathroom, and Car columns\n",
    "pd.DataFrame({'Count':data.isnull().sum()[data.isnull().sum()>0],'Percentage':(data.isnull().sum()[data.isnull().sum()>0]/data.shape[0])*100})\n",
    "\n",
    "\n",
    "#for decision trees, the data used will be binned so there are a couple of things to keep in mind\n",
    "\n",
    "#example - find missing values\n",
    "\n",
    "print(creditData.checking_balance.value_counts())\n",
    "print(creditData.credit_history.value_counts())\n",
    "print(creditData.purpose.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################CHECK OBJECTS\n",
    "\n",
    "#following the teachers example, look at all the objects and make sure they look righ\n",
    "\n",
    "for i in df.describe(include=[\"object\"]).columns:\n",
    "    print(\"Unique values in\", i, \"are :\")\n",
    "    print(df[i].value_counts())\n",
    "    print(\"*\"*50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1 if the column is a ranking or ordered type binning you could use -1 for any\n",
    "#missing or unknow values\n",
    "\n",
    "#if the binning is just random categories like: car, business, education then\n",
    "#you can use onehotencoding which is just using dummy variables on the column\n",
    "\n",
    "\n",
    "#below redefining buckets for each case\n",
    "replaceStruct = {\n",
    "                \"checking_balance\":     {\"< 0 DM\": 1, \"1 - 200 DM\": 2 ,\"> 200 DM\": 3 ,\"unknown\":-1},\n",
    "                \"credit_history\": {\"critical\": 1, \"poor\":2 , \"good\": 3, \"very good\": 4,\"perfect\": 5},\n",
    "                 \"savings_balance\": {\"< 100 DM\": 1, \"100 - 500 DM\":2 , \"500 - 1000 DM\": 3, \"> 1000 DM\": 4,\"unknown\": -1},\n",
    "                 \"employment_duration\":     {\"unemployed\": 1, \"< 1 year\": 2 ,\"1 - 4 years\": 3 ,\"4 - 7 years\": 4 ,\"> 7 years\": 5},\n",
    "                \"phone\":     {\"no\": 1, \"yes\": 2 },\n",
    "                #\"job\":     {\"unemployed\": 1, \"unskilled\": 2, \"skilled\": 3, \"management\": 4 },\n",
    "                \"default\":     {\"no\": 0, \"yes\": 1 } \n",
    "                    }\n",
    "oneHotCols=[\"purpose\",\"housing\",\"other_credit\",\"job\"]\n",
    "\n",
    "\n",
    "#reassign the values in the dataframe\n",
    "\n",
    "creditData=creditData.replace(replaceStruct)\n",
    "creditData=pd.get_dummies(creditData, columns=oneHotCols)\n",
    "creditData.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ binning out data\n",
    "\n",
    "df['Income_range'] = pd.qcut(df['Income'], q=4)\n",
    "df['Education_range'] = pd.qcut(df['Education'], q=3)\n",
    "\n",
    "inc_labels = ['Low', 'Medium', 'High']\n",
    "edu_labels = ['Low', 'Medium', 'High']\n",
    "age_labels = ['Youngest', 'Second Youngest', 'Middle', 'Second Oldest', 'Oldest']\n",
    "\n",
    "new_df['Income_label'] = pd.qcut(new_df['Income'], q=3, labels=inc_labels)\n",
    "new_df['Education_label'] = pd.qcut(new_df['Education'], q=3, labels=edu_labels)\n",
    "\n",
    "new_df.head()\n",
    "\n",
    "\n",
    "# bins and buckets\n",
    "\n",
    "# Define the bin edges and labels\n",
    "bin_edges = [18, 30, 40, 50, float('inf')]  # The last bin represents 50+\n",
    "bin_labels = [1, 2, 3, 4]\n",
    "\n",
    "# Create a new column 'Age_Category' with the bin labels\n",
    "df['Age_Category'] = pd.cut(df['Age'], bins=bin_edges, labels=bin_labels)\n",
    "\n",
    "\n",
    "\n",
    "############################. FILTERS\n",
    "\n",
    "\n",
    "#will filter the dataframe in which a columsn values are in a range\n",
    "\n",
    "df[(df['average_rating']>4.5) & (df['ratings_count']< 10)]\n",
    "\n",
    "\n",
    "\n",
    "#return a new datafram that is filterd by a value.  NOTE you need the na=False or else it will give a nana error\n",
    "\n",
    "df_eng = df[df['language_code'].str.contains('eng', na=False)]\n",
    "df_eng\n",
    "\n",
    "\n",
    "\n",
    "daw = df[(df['publisher'].str.contains('DAW', na=False)) & (df['average_rating']> 4)]\n",
    "daw['author'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39818434",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### making lists\n",
    "\n",
    "# make a list with only numerical values\n",
    "\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "#make a list that doesn't include objects\n",
    "\n",
    "columns_list = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i]!=object:\n",
    "        columns_list.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################CHECK DUPLICATES\n",
    "#check for duplicated rows\n",
    "df.duplicated().sum()\n",
    "\n",
    "# dropping duplicate entries from the data\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# this also removes duplicates, not sure what the difference is\n",
    "# it looks like this way costs more memory\n",
    "df = df[(~df.duplicated())].copy()\n",
    "\n",
    "# resetting the index of data frame since some rows will be removed\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c28853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################DROP COLUMNS AND ROWS\n",
    "\n",
    "df.drop(['ID', 'Photo', 'Flag', 'Club Logo', 'Real Face', 'Jersey Number'],axis=1,inplace=True)\n",
    "\n",
    "#It looks like wherever Bedroom is null the data points in other columns are also missing. \n",
    "#Let's check this.\n",
    "data.loc[data['Bedroom'].isnull()==True,'Bathroom'].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "\n",
    "#########if a column is a unique identifier like a social or something it can be dropped\n",
    "\n",
    "df_astro.drop(columns=['objid', 'specobjid','fiberid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################CATEGORICAL AND OBJECT VERIABLES\n",
    "\n",
    "\n",
    "# looking at value counts for non-numeric features\n",
    "\n",
    "num_to_display = 10  # defining this up here so it's easy to change later if I want\n",
    "for colname in df.dtypes[df.dtypes == 'object'].index:\n",
    "    val_counts = df[colname].value_counts(dropna=False)  # i want to see NA counts\n",
    "    print(val_counts[:num_to_display])\n",
    "    if len(val_counts) > num_to_display:\n",
    "        print(f'Only displaying first {num_to_display} of {len(val_counts)} values.')\n",
    "    print('\\n\\n') # just for more space between \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f43e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################MAKE A LIST OF NON OBJECT COLUMN NAMES\n",
    "\n",
    "#Box plot function\n",
    "\n",
    "# Defining the function for creating boxplot and hisogram \n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize)  # creating the 2 subplots\n",
    "    \n",
    "    sns.boxplot(data=data, x=feature, ax=ax_box2, showmeans=True, color=\"mediumturquoise\")  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    \n",
    "    if bins:\n",
    "      sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, color=\"mediumpurple\")\n",
    "    else: \n",
    "      sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2, color=\"mediumpurple\")  # For histogram\n",
    "    \n",
    "    ax_hist2.axvline(data[feature].mean(), color=\"green\", linestyle=\"--\")  # Add mean to the histogram\n",
    "    \n",
    "    ax_hist2.axvline(data[feature].median(), color=\"black\", linestyle=\"-\")  # Add median to the histogram\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "columns_list = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i]!=object:\n",
    "        columns_list.append(i)\n",
    "\n",
    "for i in columns_list:\n",
    "    histogram_boxplot(df,i)  #you can't use this part without the defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## note this one looks swanky\n",
    "\n",
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram\n",
    "    \n",
    "    \n",
    "##########using it\n",
    "\n",
    "# selecting numerical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "for item in num_col:\n",
    "    histogram_boxplot(df, item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################CHECK FOR DIRTY OR INCONSISTENT DATA\n",
    "\n",
    "#Example of checking columns that have the Euro symbol\n",
    "money_cols = []\n",
    "for colname in df.columns[df.dtypes == 'object']:  # only need to consider string columns\n",
    "    if df[colname].str.startswith('€').any():  # using `.str` so I can use an element-wise string method\n",
    "        money_cols.append(colname)\n",
    "print(money_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Example of standardizing inconsistent currency data\n",
    "\n",
    "def income_to_num(income_val):\n",
    "    \"\"\"This function takes in a string representing a salary in Euros\n",
    "    and converts it to a number. For example, '€220K' becomes 220000.\n",
    "    If the input is already numeric, which probably means it's NaN,\n",
    "    this function just returns np.nan.\"\"\"\n",
    "    if isinstance(income_val, str):  # checks if `income_val` is a string\n",
    "        multiplier = 1  # handles K vs M salaries\n",
    "        if income_val.endswith('K'):\n",
    "            multiplier = 1000\n",
    "        elif income_val.endswith('M'):\n",
    "            multiplier = 1000000\n",
    "        return float(income_val.replace('€', '').replace('K', '').replace('M', '')) * multiplier\n",
    "    else:  # this happens when the current income is np.nan\n",
    "        return np.nan\n",
    "\n",
    "for colname in money_cols:\n",
    "    df[colname] = df[colname].apply(income_to_num)\n",
    "    \n",
    "df[money_cols].head()  # good to go!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Example of transforming height and weight\n",
    "\n",
    "def height_to_num(height):\n",
    "    \"\"\"Converts a height of the form 5'11 (i.e. feet then inches) to inches\n",
    "    and makes it an integer. Non-string heights are treated as missing.\"\"\"\n",
    "    if isinstance(height, str):\n",
    "        splt = height.split(\"'\")\n",
    "        return float(splt[0]) * 12 + float(splt[1])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def weight_to_num(weight):\n",
    "    \"\"\"In the weight column I'm replacing the terminal 'lbs' with\n",
    "    the empty string and converting to a float. Non-strings are \n",
    "    np.nans and are kept as np.nans.\"\"\"\n",
    "    if isinstance(weight, str):\n",
    "        return float(weight.replace('lbs', ''))\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "# I could just do this by copy-pasting one line and editing which column and\n",
    "# which function I'm using for each one in turn. With only two columns\n",
    "# that's not so bad, but it gets cumbersome quickly\n",
    "\n",
    "# df['Height'] = df['Height'].apply(height_to_num)\n",
    "# df['Weight'] = df['Weight'].apply(weight_to_num)\n",
    "\n",
    "# A more general way is to collect the columns and column-processing functions\n",
    "# into a data structure and loop over that. That avoids bugs like forgetting to\n",
    "# change the second 'Height' into 'Weight' when I copy-paste the first line.\n",
    "# Here, the keys of the dictionary are the column names and the values are \n",
    "# the function that I'll use to replace that column's values. I now don't\n",
    "# have to worry about mixing up column names and processing functions.\n",
    "col_transforms = {\n",
    "    'Height': height_to_num,\n",
    "    'Weight': weight_to_num\n",
    "}\n",
    "\n",
    "# k is the key, so the column name here\n",
    "# v is the value, which a function in this case and is\n",
    "#     either `height_to_num` or `weight_to_num`\n",
    "for k,v in col_transforms.items():\n",
    "    df[k] = df[k].map(v)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Manually Replacing values\n",
    "\n",
    "df.loc[df['Body Type'] == 'PLAYER_BODY_TYPE_25', 'Body Type'] = 'Lean'\n",
    "df.loc[df['Body Type'] == 'Neymar', 'Body Type'] = 'Lean'\n",
    "df.loc[df['Body Type'] == 'Shaqiri', 'Body Type'] = 'Stocky'\n",
    "df.loc[df['Body Type'] == 'Messi', 'Body Type'] = 'Lean'\n",
    "df.loc[df['Body Type'] == 'C. Ronaldo', 'Body Type'] = 'Stocky'\n",
    "df.loc[df['Body Type'] == 'Courtois', 'Body Type'] = 'Lean'\n",
    "df.loc[df['Body Type'] == 'Akinfenwa', 'Body Type'] = 'Stocky'\n",
    "# why do these work with NaNs?\n",
    "\n",
    "df['Body Type'].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "\n",
    "#apply different calculations to rows where certains conditions are met\n",
    "\n",
    "# km/kg to kmpl conversion\n",
    "def kmpl(km_per_kg, density):\n",
    "    kmpl = km_per_kg / density\n",
    "    return kmpl\n",
    "\n",
    "# kmpl to mpg conversion\n",
    "def kmpl_to_mpg(kmpl):\n",
    "    mpg = kmpl * 2.35214583\n",
    "    return mpg\n",
    "\n",
    "\n",
    "# km/kg to mpg conversion\n",
    "def km_to_mpg(km_per_kg):\n",
    "    km_per_kg * 2.82481\n",
    "    return mpg\n",
    "\n",
    "# apply conversion functions using apply method\n",
    "df.loc[df['Mileage_unit'] == 'kmpl', 'Mileage'] = df.loc[df['Mileage_unit'] == 'kmpl', 'Mileage_value'].apply(lambda x: kmpl_to_mpg(x))\n",
    "df.loc[df['Mileage_unit'] == 'km/kg', 'Mileage'] = df.loc[df['Mileage_unit'] == 'km/kg', 'Mileage_value'].apply(lambda x: km_to_mpg(x))\n",
    "\n",
    "    \n",
    "df.head()   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############Normalizing standardizing data\n",
    "\n",
    "#Applying zscore to numerical columns in a dataframe\n",
    "\n",
    "custDataScaled=df.apply(zscore)\n",
    "custDataScaled.head(10)\n",
    "\n",
    "\n",
    "\n",
    "# Define the columns you want to normalize with z-score\n",
    "columns_to_normalize = ['Age', 'Income']\n",
    "\n",
    "# Apply z-score normalization to the selected columns\n",
    "df[columns_to_normalize] = df[columns_to_normalize].apply(zscore)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################CHANGING OR CORRECTING DATATYPES\n",
    "\n",
    "#category\n",
    "#convert categorical variables to categories\n",
    "cat_vars = ['Preferred Foot', 'Body Type', 'Position',\n",
    "            'Workrate_attack', 'Workrate_defense']\n",
    "# the other categorical variables have lots of levels\n",
    "# and I wouldn't dummy encode them as such\n",
    "\n",
    "for colname in cat_vars:\n",
    "    df[colname] = df[colname].astype('category')\n",
    "    \n",
    "df.info()\n",
    "\n",
    "\n",
    "#int\n",
    "# convert column A to integer\n",
    "df['A'] = df['A'].astype(int)\n",
    "\n",
    "\n",
    "#float\n",
    "# convert column A to float\n",
    "df['A'] = df['A'].astype(float)\n",
    "\n",
    "#string\n",
    "# convert column A to string\n",
    "df['A'] = df['A'].astype(str)\n",
    "\n",
    "#object\n",
    "# convert column A to object\n",
    "df['A'] = df['A'].astype(object)\n",
    "\n",
    "\n",
    "#example\n",
    "data['Bedroom'] = data['Bedroom'].astype(int)\n",
    "data['Bathroom'] = data['Bathroom'].astype(int)\n",
    "data['Car'] = data['Car'].astype(int)\n",
    "\n",
    "\n",
    "#Dates\n",
    "df['Joined'] = pd.to_datetime(df['Joined'])\n",
    "df['Joined year'] = df['Joined'].dt.year  # adding in a feature that's just the year\n",
    "# adding in a feature that's just the month\n",
    "df['launch_month'] = pd.to_datetime(df['launched']).dt.month \n",
    "\n",
    "\n",
    "#Check if string is made of digits\n",
    "# isdigit()? on 'horsepower' \n",
    "hpIsDigit = pd.DataFrame(cData.horsepower.str.isdigit())  # if the string is made of digits store True else False\n",
    "\n",
    "\n",
    "#replacing values\n",
    "\n",
    "cData = cData.replace('?', np.nan)\n",
    "cData[hpIsDigit['horsepower'] == False] \n",
    "\n",
    "\n",
    "#checking for non-numeric values\n",
    "\n",
    "# convert to numeric and check for missing values\n",
    "df['Price_numeric'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "has_missing = df['Price_numeric'].isna().any()\n",
    "\n",
    "if has_missing:\n",
    "    print('The Price column contains non-numeric values.')\n",
    "else:\n",
    "    print('The Price column does not contain non-numeric values.')\n",
    "    \n",
    "    \n",
    "# create a boolean mask to identify non-numeric values in 'Price' column\n",
    "mask = pd.to_numeric(df['Price'], errors='coerce').isna()\n",
    "\n",
    "# create a new DataFrame containing the rows where 'Price' is non-numeric\n",
    "non_numeric_df = df[mask]\n",
    "\n",
    "# print out the non-numeric values in the 'Price' column\n",
    "print(non_numeric_df['Price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f012e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TESTING FOR CREATING FUNCTIONS AND FOR LOOPS\n",
    "\n",
    "#This iterates through each row of a dataframe and checks if a conditiona is true or not\n",
    "#you can use something liek this to test your logic\n",
    "for index, row in df.iterrows():\n",
    "    if (row['Fuel_Type'] == 'Electric') and pd.isnull(row['Mileage_value']):\n",
    "        print(row['S.No.'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec123d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################SIMPLE DATAFRAME FUNCTIONS - CONDITIONALS\n",
    "\n",
    "#checking a column by conditional\n",
    "# investigating the players with this earliest Joined date\n",
    "df[df['Joined'] == min(df['Joined'])]\n",
    "\n",
    "\n",
    "#return a row that has value PLAYER_BODY_TYPE_25 in the Body Type column\n",
    "df[df['Body Type'] == 'PLAYER_BODY_TYPE_25']\n",
    "\n",
    "\n",
    "#return a new datafram that is filterd by a value.  NOTE you need the na=False or else it will give a nana error\n",
    "df_eng = df[df['language_code'].str.contains('eng', na=False)]\n",
    "df_eng\n",
    "\n",
    "\n",
    "#will filter the dataframe in which a columsn values are in a range\n",
    "df[(df['average_rating']>4.5) & (df['ratings_count']< 10)]\n",
    "\n",
    "\n",
    "daw = df[(df['publisher'].str.contains('DAW', na=False)) & (df['average_rating']> 4)]\n",
    "daw['author'].unique()\n",
    "\n",
    "\n",
    "df['Survived'].nunique()\n",
    "\n",
    "\n",
    "nan_count = df.isna().sum().sum()\n",
    "print(nan_count)\n",
    "\n",
    "# extracting all the information of other variables where Distance is null\n",
    "df.loc[df['Distance'].isnull()==True]\n",
    "\n",
    "#Let's see if we can find more information using the name of the Suburb.\n",
    "df.loc[df['Suburb']=='Fawkner Lot']\n",
    "\n",
    "\n",
    "df['hday'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed486b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################DROPPING ROWS\n",
    "\n",
    "# adding the index value of the row in data.drop() function\n",
    "#9560 is row 9560, see above\n",
    "data = df.drop(9590).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1c880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################SIMPLE CALULATIONS TO A COLUMN\n",
    "\n",
    "#applies a calculation to each row of Weight\n",
    "df['Weight'] = df['Weight'].apply(lambda wt: round(wt * 0.4535, 2))\n",
    "\n",
    "#pulling out where the car is Toyota\n",
    "#mtcars is the dataframe, name is the column\n",
    "mtcars['name_Toyota'] = [1 if 'Toyota' in item else 0 for item in mtcars.name]\n",
    "\n",
    "\n",
    "#count the number of student who have over 70 score\n",
    "df2 = len(df[df[\"mba_p\"]>70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################GROUPING\n",
    "\n",
    "\n",
    "#Print the mean displacement and horsepower of the cars grouped by the number of cylinders.\n",
    "mtcars.groupby('cyl')[['disp','hp']].mean()\n",
    "\n",
    "data.groupby(['stock'])['price'].mean() # will return the mean of each stock\n",
    "data['price'].median()\n",
    "data['price'].mode()\n",
    "data['price'].min()\n",
    "data['price'].max()\n",
    "\n",
    "\n",
    "df.groupby(['category'])['usd_pledged_real'].mean().reset_index().sort_values('usd_pledged_real', ascending=False)\n",
    "\n",
    "\n",
    "#sorting..you have to reset the index or else it doesn't friggin work\n",
    "after2005 = df[(df['year']> 2005)]\n",
    "maxauth= after2005.groupby('author').max()[['text_reviews_count']].sort_values('text_reviews_count', ascending=False).reset_index().head(10) \n",
    "maxauth\n",
    "\n",
    "\n",
    "df['Contract Valid Until'].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "#COUNTING VALUES BY YEAR\n",
    "contract_dates = pd.to_datetime(df['Contract Valid Until']).dt.year\n",
    "print(contract_dates.value_counts(dropna=False))\n",
    "df['Contract Valid Until'] = contract_dates\n",
    "\n",
    "# checking the average number of bedrooms, bathrooms, and car parking spaces in a region\n",
    "data.groupby(['Regionname','Type'])[['Bedroom','Bathroom','Car']].mean()\n",
    "\n",
    "\n",
    "# adding in a feature that's just the month\n",
    "df['launch_month'] = pd.to_datetime(df['launched']).dt.month \n",
    "#Obtaining the number of projects for each month\n",
    "df['launch_month'].value_counts().sort_values(ascending = False)\n",
    "\n",
    "\n",
    "df['hday'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fadce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################SORTING\n",
    "\n",
    "mtcars.sort_values(by=['mpg'], ascending=False, inplace=False)\n",
    "\n",
    "data.sort_values(by='new_price', ascending=False) #this sorts descending, ascending=True would be acending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ef78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################SLICING\n",
    "\n",
    "##Select rows from name Mazda RX4 to Valiant in the mtcars dataset and display only mpg and cyl values of those cars.\n",
    "mtcars.loc['Mazda RX4':'Valiant', 'mpg':'cyl']\n",
    "\n",
    "#Select rows from name Mazda RX4 to Valiant in the mtcars dataset and display only mpg and cyl values of those cars.\n",
    "mtcars.iloc[0:6, 1:3]\n",
    "\n",
    "\n",
    "#Select first 6 rows and first 3 columns in mtcars dataset.\n",
    "mtcars.iloc[0:6,0:3]\n",
    "\n",
    "\n",
    "# select the 3 rightmost columns\n",
    "df.iloc[:, -5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b52e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################LEFT JOIN\n",
    "\n",
    "df6 = pd.merge(df1,df2,how='right',on='customerID') #is like a left join on like values df2 onto df1\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad586a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################UNION\n",
    "\n",
    "df5 = pd.merge(df1,df2,how='inner',on='customerID') #unions where values are alike, OMITS unlike values\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################UNION ALL\n",
    "\n",
    "df4 = pd.merge(df1,df2,how='outer',on='customerID') #unions ALL where values are alike, unknown values are nulled\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################COLUMN SPLIT BY DELIMITER\n",
    "\n",
    "workrt = df[\"Work Rate\"].str.split(\"/ \", n = 1, expand = True) \n",
    "workrt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CDF\n",
    "## this is realy good to check counts by percentage, and skewness of data\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 15))\n",
    "fig.suptitle(\"CDF plot of numerical variables\", fontsize=20)\n",
    "counter = 0\n",
    "for ii in range(3):\n",
    "    sns.ecdfplot(ax=axes[ii][0], x=df[num_col[counter]])\n",
    "    counter = counter + 1\n",
    "    if counter != 5:\n",
    "        sns.ecdfplot(ax=axes[ii][1], x=df[num_col[counter]])\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "fig.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################UNIVARIATE ANALYSIS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Strip Plot\n",
    "A strip plot is basically a scatter plot that differentiates different categories.\n",
    "The stripplot() function of seaborn can be used to make a strip plot.\n",
    "\n",
    "\n",
    "SCatter plot of just one variable\n",
    "\"\"\"\n",
    "\n",
    "sns.stripplot(data=df, x='engine_size');\n",
    "\n",
    "\n",
    "sns.histplot(data=df,x='Distance',stat='density')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df,x='Distance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the count of each category\n",
    "make_counts = df['Make'].value_counts()\n",
    "\n",
    "# Sort the categories by count in descending order\n",
    "sorted_makes = make_counts.index\n",
    "\n",
    "# Create the count plot with sorted categories\n",
    "sns.countplot(data=df, x='Make', order=sorted_makes)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#remove outliers from boxblot\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df,x='Type',y='Price',showfliers=False) # turning off outliers\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#bowplot by category, remove outliers\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df,x='Regionname',y='Price',showfliers=False) # turning off outliers\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#violin plot\n",
    "# Dispersion of price in every region\n",
    "sns.catplot(x='Price',\n",
    "            col='Regionname', \n",
    "            data=df,\n",
    "            col_wrap=4,\n",
    "            kind=\"violin\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#countplot\n",
    "sns.countplot(data=df,x='hday');\n",
    "#The number of pickups is more on non-holidays than on holidays\n",
    "\n",
    "sns.countplot(data=df,x='borough');\n",
    "plt.xticks(rotation = 90)\n",
    "#The observations are uniformly distributed across the boroughs except the observations that had NaN values \n",
    "#and were attributed to Unknown borough\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################### making lists\n",
    "\n",
    "# make a list with only numerical values\n",
    "\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "#make a list that doesn't include objects\n",
    "\n",
    "columns_list = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i]!=object:\n",
    "        columns_list.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781cc570",
   "metadata": {},
   "source": [
    "## list of palette colors\n",
    "\n",
    "\"deep\"\n",
    "\"muted\"\n",
    "\"pastel\"\n",
    "\"dark\"\n",
    "\"colorblind\"\n",
    "\"Set1\"\n",
    "\"Set2\"\n",
    "\"Set3\"\n",
    "\"husl\"\n",
    "\"cubehelix\"\n",
    "\"RdBu_r\"\n",
    "\"coolwarm\"\n",
    "\"viridis\"\n",
    "\"plasma\"\n",
    "\"inferno\"\n",
    "\"magma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb16e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################.   UNIVARIATE FUNCTIONS\n",
    "\n",
    "\n",
    "#This is to check the ratio in a column, especially for target values\n",
    "\n",
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot\n",
    "    \n",
    "\n",
    "    \n",
    "### version 2 labeled barplot\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot\n",
    "    \n",
    "# let's explore discounts further\n",
    "labeled_barplot(df, \"Discount\", perc=True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "###.  creating histogram\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# make a list that doesn't include objects\n",
    "columns_list = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i] != object:\n",
    "        columns_list.append(i)\n",
    "\n",
    "for variable in columns_list:\n",
    "    histogram_boxplot(df, variable)\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Bivariate \n",
    "\n",
    "# Stacked Barplot\n",
    "\n",
    "# function to plot stacked bar chart\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6a67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################BIVARIATE ANALYSIS\n",
    "\n",
    "sns.pairplot(data=df[num_col], diag_kind=\"kde\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#CORRELATION AND DISTRIBUTION\n",
    "\n",
    "#correlation\n",
    "# Check for correlation among numerical variables\n",
    "num_var = ['pickups','spd','vsb','temp','dewp', 'slp','pcp01', 'pcp06', 'pcp24', 'sd']\n",
    "\n",
    "corr = df[num_var].corr()\n",
    "\n",
    "# plot the heatmap\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(corr, annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#this one removes the 1 correlations due to variables being compared to each other\n",
    "# Create correlation matrix\n",
    "corr_mat = df.corr(method='pearson')\n",
    "\n",
    "# Drop correlations where the variable names are the same\n",
    "corr_mat = corr_mat.mask(np.tril(np.ones_like(corr_mat, dtype=bool)))\n",
    "\n",
    "# Convert correlation matrix to 1-D Series and sort\n",
    "sorted_mat = corr_mat.unstack().drop_duplicates().sort_values()\n",
    "\n",
    "# Remove correlations with a value of 1 or null values\n",
    "sorted_mat = sorted_mat[(sorted_mat != 1) & (~sorted_mat.isnull())]\n",
    "\n",
    "print(sorted_mat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#correlation\n",
    "df['is_GK'] = df['Position'] == 'GK'  # for hue\n",
    "cols_to_exclude = ['International Reputation', 'Weak Foot', 'Skill Moves']\n",
    "sns.pairplot(df[[colname for colname in df.columns if colname not in cols_to_exclude]], hue = 'is_GK')\n",
    "df.drop(['is_GK'], axis=1, inplace=True)\n",
    "\n",
    "#correlation\n",
    "df.corr()\n",
    "\n",
    "#paitplot\n",
    "sns.pairplot(data=df[num_var], diag_kind=\"kde\")\n",
    "plt.show()\n",
    "\n",
    "#Pairplot\n",
    "sns.pairplot(data=df[['normalized_losses','wheel_base','curb_weight','engine_size',\n",
    "                      'price','peak_rpm']])\n",
    "\n",
    "#correlation\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='Spectral',vmin=-1,vmax=1)\n",
    "plt.show()\n",
    "\n",
    "#scatterplot\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(data=df,x='Total Space',y='Price')\n",
    "plt.show()\n",
    "\n",
    "#scatterplot with trend line\n",
    "sns.lmplot(data=df,x='Total Space',y='Price',height=5,aspect=2)\n",
    "plt.xlim(0,55)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Strip plots are more useful when we add random noise called \"jitter\" to avoid \n",
    "overlapping of data points with same values.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.stripplot(data=df, x='body_style', y='engine_size', jitter=True);\n",
    "\n",
    "\n",
    "\n",
    "#catplot swarm\n",
    "\n",
    "sns.catplot(data=df, x=\"number_of_doors\", y=\"price\", hue=\"body_style\", \n",
    "            col=\"fuel_type\", kind='swarm', palette='muted');\n",
    "\n",
    "#catplot swarm with dodge - makes the plots side by side instead of merged - a little clearer\n",
    "sns.swarmplot(data=df, x='fuel_type', y='price', hue='number_of_doors', dodge=True);\n",
    "\n",
    "\n",
    "\n",
    "#catplot box - I like this one a lot\n",
    "\n",
    "sns.catplot(data=df, x=\"fuel_type\", y=\"engine_size\", hue=\"body_style\", \n",
    "            col=\"number_of_doors\", kind='box', palette='bright');\n",
    "\n",
    "\n",
    "#catplot bar\n",
    "\n",
    "sns.catplot(data=df, x=\"fuel_type\", y=\"horsepower\", hue=\"number_of_doors\", col=\"drive_wheels\", kind='bar', palette='pastel');\n",
    "\n",
    "\n",
    "\n",
    "#catplot point - this one is interesting\n",
    "sns.catplot(data=df, x='body_style', y='horsepower', hue='fuel_type', kind='point');\n",
    "\n",
    "\n",
    "#catplot stripplot\n",
    "sns.catplot(data=df, x='fuel_type', y='horsepower');\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#line plot\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x='Distance', y ='Price',ci=None)\n",
    "plt.show()\n",
    "\n",
    "#Line plot by region\n",
    "sns.relplot(data=df,x='AgeofProp',y='Price',col='Regionname',kind='line', ci=None, col_wrap=4)\n",
    "plt.show()\n",
    "# double click on the plot to zoom in\n",
    "\n",
    "\n",
    "\n",
    "#line plot..time series\n",
    "\n",
    "cats = df.start_month.unique().tolist()\n",
    "df.start_month = pd.Categorical(df.start_month, ordered=True, categories=cats)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x=\"start_month\", y=\"pickups\", ci=False, color=\"red\", estimator='sum')\n",
    "plt.ylabel('Total pickups')\n",
    "plt.xlabel('Month')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x=\"start_day\", y=\"pickups\", estimator='sum', ci=False, color=\"red\")\n",
    "plt.ylabel('Total pickups')\n",
    "plt.xlabel('Day of Month')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x=\"start_hour\", y=\"pickups\", estimator='sum', ci=False, color=\"red\")\n",
    "plt.ylabel('Total pickups')\n",
    "plt.xlabel('Hour of the day')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cats = ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df.week_day = pd.Categorical(df.week_day, ordered=True, categories=cats)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x=\"week_day\", y=\"pickups\", ci=False, color=\"red\", estimator='sum')\n",
    "plt.ylabel('Total pickups')\n",
    "plt.xlabel('Weeks')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Pickups across Borough\n",
    "plt.figure(figsize=(15,7))           \n",
    "sns.boxplot(x=df['borough'], y=df['pickups'])\n",
    "plt.ylabel('pickups')\n",
    "plt.xlabel('Borough')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Dispersion of pickups in every borough\n",
    "sns.catplot(x='pickups', col='borough', data=df, col_wrap=4, kind=\"violin\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#barplot\n",
    "sns.catplot(x='hday', y='pickups', data=df, kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "#The mean pickups on a holiday is lesser than that on a non-holiday\n",
    "\n",
    "\n",
    "\n",
    "cData_attr = cData.iloc[:, 0:7]\n",
    "sns.pairplot(cData_attr, diag_kind='kde') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#has scatter and bar\n",
    "sns.jointplot(data=df, x='price', y='city_mpg', kind=\"reg\");\n",
    "\n",
    "\n",
    "sns.jointplot(data=df, x='engine_size', y='horsepower');\n",
    "\n",
    "\n",
    "#hex\n",
    "sns.jointplot(data=df, x='engine_size', y='horsepower', kind=\"hex\");\n",
    "plt.colorbar(); # adds a separate axis indicating the color scale in this plot\n",
    "\n",
    "\n",
    "#scaterplot with trendline\n",
    "\n",
    "#lmplot is linear model plot\n",
    "sns.lmplot(data=df, x='horsepower', y='price', ci=False);\n",
    "\n",
    "\n",
    "#lmplot is linear model plot\n",
    "sns.lmplot(data=df, x='curb_weight', y='engine_size', col='number_of_doors', ci=False)\n",
    "\n",
    "#style optional\n",
    "sns.scatterplot(data=df, x='engine_size', y='horsepower', hue='fuel_type', style='fuel_type');\n",
    "\n",
    "\n",
    "#line chart with stacked categories\n",
    "plt.figure(figsize = (15,7))\n",
    "sns.lineplot(data = flights , x = 'month' , y = 'passengers', hue = 'year')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.legend(bbox_to_anchor=[1, 1]); #another way to change the legend's location in the plot\n",
    "\n",
    "\n",
    "\n",
    "#jointplot\n",
    "sns.pairplot(data=df, vars=['wheel_base', 'curb_weight', 'engine_size', 'price'], \n",
    "             hue='number_of_doors');\n",
    "\n",
    "\n",
    "sns.pairplot(data=df[['normalized_losses','wheel_base','curb_weight','engine_size',\n",
    "                      'price','peak_rpm']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 2, 6))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 2, 6))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# function to plot stacked bar chart\n",
    "\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 6))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "    \n",
    "stacked_barplot(loan, \"term\", \"isDelinquent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7796480",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How to choose between classification algorithms\n",
    "\n",
    "### Metrics\n",
    "\n",
    "Accuracy: Gives a general idea of how well the model performs, but may be misleading if the classes are imbalanced.\n",
    "\n",
    "Recall: Important when you want to minimize false negatives. E.g., in medical diagnosis, you wouldn't want to miss any positive cases.\n",
    "\n",
    "Precision: Important when you want to minimize false positives. E.g., in spam detection, you wouldn't want to flag legitimate emails as spam.\n",
    "\n",
    "F1 Score: Harmonic mean of precision and recall. Useful when you want a balance between precision and recall.\n",
    "\n",
    "ROC-AUC : Measures the area under the ROC curve, which is a plot of True Positive Rate vs False Positive Rate at various thresholds. AUC gives an aggregate measure of performance across all possible classification thresholds. An AUC of 1 is perfect, and 0.5 is no better than random guessing.\n",
    "\n",
    "\n",
    "\n",
    "## Classification\n",
    "\n",
    "There are numerous classification algorithms, and each has its strengths and weaknesses. To select the best algorithm for a specific problem, I recommend trying multiple algorithms and compare their performance using cross-validation and other evaluation metrics. This process, known as model selection, helps you choose the algorithm that best suits your problem and dataset. This process is also called stacking classifiers. sklearn.ensemble.StackingClassifier — scikit-learn 1.3.1 documentation\n",
    "\n",
    "1. Logistic Regression\n",
    "\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "\n",
    "3. Support Vector Machines (SVM)\n",
    "\n",
    "4. Naive Bayes Classifier\n",
    "\n",
    "5. Decision Trees\n",
    "\n",
    "6. Random Forests\n",
    "\n",
    "7. Gradient Boosting Machines (GBM)\n",
    "\n",
    "8. Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "9. LightGBM\n",
    "\n",
    "10. CatBoost\n",
    "\n",
    "11. Neural Networks (Deep Learning)\n",
    "\n",
    "Selecting the right algorithm depends on various factors, such as:\n",
    "\n",
    "Problem complexity: Choose a simpler algorithm like logistic regression or KNN for linearly separable problems. For more complex problems, consider using SVM, decision trees, or neural networks.\n",
    "\n",
    "Size of the dataset: For large datasets, consider using more efficient algorithms such as XGBoost, LightGBM, or CatBoost. For smaller datasets, SVM or KNN may work well.\n",
    "\n",
    "Interpretability: If you need an easily interpretable model, consider using logistic regression, decision trees, or Naive Bayes. For more accurate but less interpretable models, consider using SVM, random forests, or neural networks.\n",
    "\n",
    "Speed and computational resources: Some algorithms, like neural networks, require more computational resources and longer training times. Choose an algorithm that fits within your resource constraints.\n",
    "\n",
    "Quality of the data: Some algorithms, like Naive Bayes, are more robust to noisy data. If your dataset has a lot of noise, consider using such algorithms.\n",
    "\n",
    "Overfitting: Some algorithms are more prone to overfitting, such as decision trees. To avoid overfitting, consider using regularization techniques or ensemble methods like random forests or gradient boosting machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Calulate F1 Score, accuracy, recall, precision\n",
    "\n",
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"F1\": f1,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf\n",
    "\n",
    "\n",
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "######. Creating a decision tree model\n",
    "\n",
    "decision_tree_perf_train = model_performance_classification_sklearn(\n",
    "    model, X_train, y_train\n",
    ")\n",
    "decision_tree_perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26257bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTLIERS - CRIM, B\n",
    "\n",
    "#################################OUTLIER TEST\n",
    "\n",
    "# outlier detection using boxplot - UNIVARIATE FIRST\n",
    "# selecting the numerical columns of data and adding their names in a list \n",
    "numeric_columns = ['CRIM', 'B']\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, variable in enumerate(numeric_columns):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.boxplot(df[variable], whis=1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#IQR\n",
    "\n",
    "# to find the 25th percentile and 75th percentile for the numerical columns.\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1                   #Inter Quantile Range (75th percentile - 25th percentile)\n",
    "\n",
    "lower_whisker = Q1 - 1.5*IQR    #Finding lower and upper bounds for all values. All values outside these bounds are outliers\n",
    "upper_whisker = Q3 + 1.5*IQR\n",
    "\n",
    "# Percentage of outliers in each column\n",
    "((df[numeric_columns] < lower_whisker) | (df[numeric_columns] > upper_whisker)).sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################TREATING OUTLIERS\n",
    "\n",
    "#IQR\n",
    "\n",
    "def treat_outliers(df, col):\n",
    "    \"\"\"\n",
    "    treats outliers in a variable\n",
    "    col: str, name of the numerical variable\n",
    "    df: dataframe\n",
    "    col: name of the column\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)  # 25th quantile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th quantile\n",
    "    IQR = Q3 - Q1                # Inter Quantile Range (75th perentile - 25th percentile)\n",
    "    lower_whisker = Q1 - 1.5 * IQR\n",
    "    upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "    # all the values smaller than lower_whisker will be assigned the value of lower_whisker\n",
    "    # all the values greater than upper_whisker will be assigned the value of upper_whisker\n",
    "    # the assignment will be done by using the clip function of NumPy\n",
    "    df[col] = np.clip(df[col], lower_whisker, upper_whisker)\n",
    "\n",
    "    return df\n",
    "\n",
    "#check the outliers\n",
    "\n",
    "#Treating outliers in Rooms column\n",
    "\n",
    "data = treat_outliers(data,'Rooms')\n",
    "\n",
    "# visualizing the column after outlier treatment\n",
    "# outlier detection using boxplot\n",
    "# selecting the numerical columns where outliers were treated \n",
    "numeric_columns = ['Rooms', 'Bedroom', 'Bathroom', 'Car','Landsize']\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, variable in enumerate(numeric_columns):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.boxplot(df[variable], whis=1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#zscores\n",
    "#you could filter the column where it is withing 3 standard deviations\n",
    "df['A_zscore'] = zscore(df['A'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1230536",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################MULTIVARIATE ANALYSIS\n",
    "\n",
    "#BARPLOT WITH HUE CATEGORY\n",
    "sns.catplot(x='borough', y='pickups', data=df, kind=\"bar\", hue='hday')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Stacked LINE CHART BY CATEGORY\n",
    "#Since we have seen that borough has a significant effect on the number of pickups, let's check if that effect \n",
    "#is present across different hours of the day.\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.lineplot(data=df, x=\"start_hour\", y=\"pickups\", hue='borough', estimator='sum', ci=False)\n",
    "plt.ylabel('Total pickups')\n",
    "plt.xlabel('Hour of the day')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb89485",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################CREATE DUMMY VARIABLES\n",
    "\n",
    "cData = pd.get_dummies(cData, columns=['origin'])\n",
    "cData.head()\n",
    "\n",
    "\n",
    "df2 = pd.get_dummies(df\n",
    "               ,columns = ['region', 'sex', 'smoker']\n",
    "               ,drop_first = True\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################FINDING THE BEST VARIABLES TO USE IN YOUR PREDICTION MODEL\n",
    "\n",
    "\"\"\"\n",
    "You can't just plug everything you have into the regression model\n",
    "\n",
    "You have to select the best candidates for the model to make the model as accurate as possible\n",
    "\n",
    "I think it's best to automate this instead of manualy selecting candidates\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Filter out variables with correlation coefficients above 50% or below -50%\n",
    "high_corr_vars = corr_matrix[abs(corr_matrix) > 0.5].stack().reset_index()\n",
    "high_corr_vars = high_corr_vars[high_corr_vars['level_0'] != high_corr_vars['level_1']]\n",
    "high_corr_vars = high_corr_vars.drop_duplicates(subset=[0])\n",
    "high_corr_vars.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "high_corr_vars = high_corr_vars.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "corr_list = high_corr_vars[['Variable 1', 'Variable 2']].values.flatten().tolist()\n",
    "corr_list = list(set(corr_list))\n",
    "\n",
    "# Print the variables that have correlation coefficients above 50% or below -50%\n",
    "#of course you can reset the % correlation as needed to improve the model\n",
    "print(corr_list)\n",
    "\n",
    "#Of course, it's probably going to include the variable we are going to use to predict so we will have\n",
    "#to remove it\n",
    "\n",
    "corr_list.remove('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbaea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####. CHECK FOR INBALANCED CLASSES\n",
    "\n",
    "# To undersample and oversample the data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "######OverSampling - feature engineering\n",
    "\n",
    "# checking the distribution of the target variable\n",
    "data[\"target\"].value_counts(1)\n",
    "\n",
    "#note Chatgpt said it is important to check the balances for the x variables too, but for now just focus on y\n",
    "\n",
    "# Predicting the target for train and validation set\n",
    "pred_train = dtree.predict(X_train)\n",
    "pred_val = dtree.predict(X_val)\n",
    "# Checking recall score on oversampled train and validation set\n",
    "print(recall_score(y_train, pred_train))\n",
    "print(recall_score(y_val, pred_val))\n",
    "\n",
    "\n",
    "# Checking accuracy score on oversampled train and validation set\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "\n",
    "\n",
    "# Fit SMOTE on train data(Synthetic Minority Oversampling Technique)\n",
    "sm = SMOTE(sampling_strategy=0.4, k_neighbors=5, random_state=1)\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Before OverSampling, count of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, count of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "print(\"After OverSampling, count of label '1': {}\".format(sum(y_train_over == 1)))\n",
    "print(\"After OverSampling, count of label '0': {} \\n\".format(sum(y_train_over == 0)))\n",
    "\n",
    "print(\"After OverSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
    "print(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################   Under sampling\n",
    "\n",
    "# fit random under sampler on the train data\n",
    "rus = RandomUnderSampler(random_state=1, sampling_strategy = 1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before Under Sampling, count of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before Under Sampling, count of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "print(\"After Under Sampling, count of label '1': {}\".format(sum(y_train_un == 1)))\n",
    "print(\"After Under Sampling, count of label '0': {} \\n\".format(sum(y_train_un == 0)))\n",
    "\n",
    "print(\"After Under Sampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
    "print(\"After Under Sampling, the shape of train_y: {} \\n\".format(y_train_un.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### K-FOLD KFOLD\n",
    "\n",
    "# to create k folds of data and get cross validation score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\"\"\"\n",
    "k-fold is a technique used for model evaluation and validation in machine learning. It helps to assess \n",
    "the performance and generalization ability of a model by splitting the dataset into multiple subsets or folds.\n",
    "\n",
    "Here's how the k-fold cross-validation process works:\n",
    "\n",
    "The original dataset is divided into k equal-sized folds or subsets.\n",
    "The model is trained and evaluated k times, each time using a different fold as the validation set and the\n",
    "remaining k-1 folds as the training set.\n",
    "The performance metrics (such as accuracy, precision, recall, or F1-score) are calculated for each \n",
    "iteration or fold.\n",
    "The performance results from all k iterations are then averaged to obtain a more robust estimation of \n",
    "the model's performance.\n",
    "The key benefits of k-fold cross-validation are as follows:\n",
    "\n",
    "More reliable performance estimate: By repeating the training and evaluation process on different subsets\n",
    "of the data, k-fold cross-validation provides a more reliable estimate of the model's performance compared \n",
    "to a single train-test split.\n",
    "\n",
    "Effective use of data: It allows the model to be trained and evaluated on the entire dataset, ensuring that\n",
    "all instances are used for both training and evaluation.\n",
    "\n",
    "Better assessment of model generalization: Since the model is evaluated on multiple different validation sets, \n",
    "k-fold cross-validation provides insights into how the model generalizes to unseen data. It helps identify issues \n",
    "like overfitting or underfitting.\n",
    "\n",
    "Common choices for the value of k are 5 and 10, but it can be adjusted depending on the dataset size and\n",
    "computational resources available. Typically, larger values of k provide more reliable performance estimates\n",
    "but require more computational resources.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# defining kfold\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle = True)\n",
    "\n",
    "# number of splits = 10\n",
    "\n",
    "\n",
    "# defining the model just using Logistic regression as an example\n",
    "model = LogisticRegression(random_state = 1)\n",
    "\n",
    "# storing accuracy values of model for every fold in \"results\"\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################RIDGE AND LASSO - Feature engineering\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "In feature engineering, Ridge and Lasso are regularization techniques commonly used in linear \n",
    "regression models. They help address potential issues like overfitting, multicollinearity, \n",
    "and feature selection by introducing a penalty term to the loss function. Both Ridge and Lasso \n",
    "aim to reduce the complexity of the model and improve its generalization ability.\n",
    "\n",
    "\n",
    "Ridge Regression:\n",
    "\n",
    "Ridge regression adds a regularization term to the least squares loss function, which is the sum of \n",
    "squared residuals. The regularization term is a penalty based on the magnitude of the model's coefficients.\n",
    "Ridge regression encourages the coefficients to be small, which helps to reduce the impact of individual \n",
    "features and mitigate the effects of multicollinearity (high correlation) among features.\n",
    "By shrinking the coefficients, Ridge regression can help prevent overfitting by reducing model complexity \n",
    "and improving generalization.\n",
    "Ridge regression does not perform feature selection, as it tends to keep all the features in the model,\n",
    "albeit with reduced coefficients.\n",
    "Lasso Regression:\n",
    "\n",
    "Lasso regression, similar to Ridge regression, adds a regularization term to the least squares loss function. \n",
    "However, the regularization term in Lasso is the sum of the absolute values of the coefficients, also known \n",
    "as the L1 penalty.\n",
    "Lasso regression not only encourages small coefficient values but also has the property of feature selection.\n",
    "It can drive some of the coefficients to exactly zero, effectively removing the corresponding features from \n",
    "the model.\n",
    "By eliminating irrelevant or redundant features, Lasso regression can simplify the model, enhance \n",
    "interpretability, and potentially improve predictive performance.\n",
    "Lasso is particularly useful when dealing with datasets that contain a large number of features,\n",
    "as it can automatically perform feature selection and identify the most important predictors.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887be64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################LINEAR REGRESSION\n",
    "\n",
    "\n",
    "# lets build our linear model\n",
    "# independant variables\n",
    "X = cData.drop(['bmi'], axis=1)\n",
    "# the dependent variable\n",
    "y = cData[['bmi']]\n",
    "\n",
    "\n",
    "\n",
    "#Or include columns, I'd rather use this way so I have control over the variables that go in\n",
    "\n",
    "# Define a list of column names to include in X\n",
    "included_cols = ['age', 'sex', 'bmi_category', 'blood_pressure']\n",
    "\n",
    "# Set X to include only the columns in included_cols\n",
    "X = cData[included_cols]\n",
    "\n",
    "# Set y to the target variable\n",
    "y = cData['bmi']\n",
    "\n",
    "# Split X and y into training and test set in 70:30 ratio\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#interpret with caution.  when x goes up what does y do?\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))\n",
    "    \n",
    "    \n",
    "# so with those coeficients above you COULD calculate the R^2 using the formula y = x +x2 + x3\n",
    "#the function below does that for you to get the R^2\n",
    "regression_model.score(X_train, y_train)\n",
    "\n",
    "\n",
    "#out of sample score (R^2)\n",
    "\n",
    "regression_model.score(X_test, y_test)\n",
    "\n",
    "# so the score below looks pretty good but how do we know it's not overfit?  We improve it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda46296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################POLYNOMIAL TRANSFORMATION ON LINEAR MODEL\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "#The below adds a bunch of new variables which WILL increase the R^2 value.  Adding more variables will always increas\n",
    "#the R^2 but will not always improve the model.  See how the training R^2 jumps up to 90% but the test set only goe sup\n",
    "#by 2 points to 86%\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train2 = poly.fit_transform(X_train)\n",
    "X_test2 = poly.fit_transform(X_test)\n",
    "\n",
    "poly_clf = linear_model.LinearRegression()\n",
    "\n",
    "poly_clf.fit(X_train2, y_train)\n",
    "\n",
    "y_pred = poly_clf.predict(X_test2)\n",
    "\n",
    "#print(y_pred)\n",
    "\n",
    "#In sample (training) R^2 will always improve with the number of variables!\n",
    "print(poly_clf.score(X_train2, y_train))\n",
    "\n",
    "\n",
    "\n",
    "#Out off sample (testing) R^2 is our measure of sucess and does improve\n",
    "print(poly_clf.score(X_test2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CORRELATION PEARSON\n",
    "\n",
    "r = np.corrcoef(cData['charges'], cData['children'])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of Explained Variance\n",
    "#The result should be between 0 and 1 for the model to be meaningful\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "predictions = linear_regression.predict(X_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(linear_regression, X, y, cv=10, scoring=\"explained_variance\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### LOGISTIC REGRESSION\n",
    "\n",
    "\n",
    "\n",
    "### Train and split the data\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Status',axis=1)     # Predictor feature columns (8 X m)\n",
    "Y = df['Status']   # Predicted class (1=True, 0=False) (1 X m)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "# 1 is just any random seed number\n",
    "\n",
    "x_train.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#count percentage of each category\n",
    "y_test.value_counts(normalize=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "cm=metrics.confusion_matrix(y_train, y_predict, labels=[1, 0])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual 1\",\" Actual 0\"]],\n",
    "                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True,fmt='g')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# get intercept for model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit the model on train\n",
    "model = LogisticRegression(solver=\"liblinear\", random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "#predict on test\n",
    "y_predict = model.predict(x_train)\n",
    "\n",
    "\n",
    "coef_df = pd.DataFrame(model.coef_)\n",
    "coef_df['intercept'] = model.intercept_\n",
    "print(coef_df)\n",
    "\n",
    "\n",
    "#score for the test data\n",
    "model_score = model.score(x_test, y_test)\n",
    "print(model_score)\n",
    "\n",
    "\n",
    "#further testing of accuracy of model\n",
    "\n",
    "\"\"\"\n",
    "Actual \\ Predicted\tPositive\t        Negative\n",
    "Positive\t        True Positive (TP)\tFalse Negative (FN)\n",
    "Negative\t        False Positive (FP)\tTrue Negative (TN)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Accuracy = TN + TP / TM + FN + TP + FP\n",
    "    Accuracy is a very good measure if negative and positive classes have the same number of data instances, \n",
    "    which means that the data is balanced. In reality, we can hardly find balanced data for classification tasks.\n",
    "    accuracy = 1 - error rate\n",
    "REcall (sensitivity or true positive rate) = TP / TP + FN\n",
    "    Recall can be used as a measure in such cases, where Overlooked Cases (False Negatives) are more costly\n",
    "    and the focus is on finding the positive cases.\n",
    "    Recall, Sensitivity, and True Positive Rate are the same thing.\n",
    "    most appropriate to evaluate the model according to the probelm statement\n",
    "PREcision = TP / TP + FP\n",
    "    Precision is a good evaluation metric to use when the cost of a false positive is very high and the cost \n",
    "    of a false negative is low. Let’s understand this with the help of an example\n",
    "F1 Score = 2 + PRecision * Recall / PRecision + Recall\n",
    "    F1 score is the combination of Precision and Recall. If we want our model to be correct and not miss any \n",
    "    correct predictions, then we want to maximize both Precision and Recall scores. There comes F1 score.\n",
    "\n",
    "CLassification error rate = sum(Type 1 or FP) and sum(Type 2 errors or FN), accuracy = 1 - error rate\n",
    "    FP + FN / TP + FP + FN + TN\n",
    "\n",
    "Specificity (True NEgative RAte) - proportion of all negatives that were correctly identified\n",
    "    TN / TN + FP \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Decision Tree - CLassification\n",
    "####PRobably better to use Random forrest and Decision trees tend to overfit\n",
    "\n",
    "##########. Y / N,   Get's the loan or no\n",
    "\n",
    "\n",
    "########### Note all the columns are going to be categorical for this type of model\n",
    "#so when you do your preprocessing you will need to either use dummy variables\n",
    "#or replace them with numerical values\n",
    "\n",
    "\n",
    "##########. Note, the more complex a tree, the more prone to overfitting\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "\n",
    "#check the shape of the train and test set\n",
    "print(\"Number of rows in train data =\", X_train.shape[0])\n",
    "print(\"Number of rows in test data =\", X_test.shape[0])\n",
    "\n",
    "\n",
    "#CHeck the proportion of each\n",
    "print(\"Percentage of classes in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"Percentage of classes in test set:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "\n",
    "#build gini ctrieria to split\n",
    "\n",
    "dTree = DecisionTreeClassifier(criterion = 'gini', random_state=1)\n",
    "dTree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#check Accuracy of model - should be as close to 1 as possible\n",
    "#not a good measure for models if the data is not well balanced\n",
    "#should also use precision, recall and/or F1 score\n",
    "\"\"\"\n",
    "Accuracy = TN + TP / TM + FN + TP + FP\n",
    "    Accuracy is a very good measure if negative and positive classes have the same number of data instances, \n",
    "    which means that the data is balanced. In reality, we can hardly find balanced data for classification tasks.\n",
    "    accuracy = 1 - error rate\n",
    "\"\"\"\n",
    "print(\"Accuracy on training set : \",dTree.score(X_train, y_train))\n",
    "print(\"Accuracy on test set : \",dTree.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#say we are calculating scores for a bank - they want to minimize loss, so we also want to check recall\n",
    "#Recall - It gives the ratio of True positives to Actual positives, so high Recall implies low false negatives, \n",
    "#i.e. low chances of predicting a defaulter as non defaulter\n",
    "\n",
    "\n",
    "\n",
    "## Function to create confusion matrix\n",
    "def make_confusion_matrix(model,y_actual,labels=[1, 0]):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "    y_actual : ground truth  \n",
    "    \n",
    "    '''\n",
    "    y_predict = model.predict(X_test)\n",
    "    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[0, 1])\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual - No\",\"Actual - Yes\"]],\n",
    "                  columns = [i for i in ['Predicted - No','Predicted - Yes']])\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "              zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=labels,fmt='')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "##  Function to calculate recall score\n",
    "def get_recall_score(model):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n",
    "    print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n",
    "    \n",
    "\n",
    "# Recall on train and test\n",
    "get_recall_score(dTree)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X = ['checking_balance', 'months_loan_duration', 'credit_history', 'amount', 'savings_balance', \n",
    "'employment_duration', 'percent_of_income', 'years_at_residence', 'age', 'existing_loans_count', \n",
    "'dependents', 'phone', 'purpose_business', 'purpose_car', 'purpose_car0', 'purpose_education', \n",
    "'purpose_furniture/appliances', 'purpose_renovations', 'housing_other', 'housing_own', 'housing_rent', \n",
    "'other_credit_bank', 'other_credit_none', 'other_credit_store', 'job_management', 'job_skilled', \n",
    "'job_unemployed', 'job_unskilled']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################Go through these steps, and configure the tree untill you get accuracy and recall scores\n",
    "################YOu are happy with     \n",
    "\n",
    "#visualize the decision tree\n",
    "feature_names = list(X.columns)  #assign the categorial columns to a variable \n",
    "print(feature_names)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "tree.plot_tree(dTree,feature_names=feature_names,filled=True,fontsize=9,node_ids=True,class_names=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this will show textually the rules of how the splits were made\n",
    "print(tree.export_text(dTree,feature_names=feature_names,show_weights=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sort the importance of features\n",
    "\n",
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print (pd.DataFrame(dTree.feature_importances_, columns = [\"Imp\"], index = X_train.columns).sort_values(by = 'Imp', ascending = False))\n",
    "\n",
    "\n",
    "#look at it in barchart form\n",
    "\n",
    "importances = dTree.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#reduce overfitting.  we can reduce the depth to make the model more simple\n",
    "\n",
    "dTree1 = DecisionTreeClassifier(criterion = 'gini',max_depth=3,random_state=1)\n",
    "dTree1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy and recall on train and test\n",
    "print(\"Accuracy on training set : \",dTree1.score(X_train, y_train))\n",
    "print(\"Accuracy on test set : \",dTree1.score(X_test, y_test))\n",
    "# Recall on train and test\n",
    "get_recall_score(dTree1)\n",
    "\n",
    "\n",
    "#################Go through these steps, and configure the tree untill you get accuracy and recall scores\n",
    "################YOu are happy with  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################Pre-prunning\n",
    "########You could try 2 different datasets for pre-prunning and post-prunning to see if one results\n",
    "#better than the other?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Using GridSearch for Hyperparameter tuning of our tree model\n",
    "\n",
    "Hyperparameter tuning is also tricky in the sense that there is no direct way to calculate how a change \n",
    "in the hyperparameter value will reduce the loss of your model, so we usually resort to experimentation. \n",
    "i.e we'll use Grid search\n",
    "Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.\n",
    "It is an exhaustive search that is performed on a the specific parameter values of a model.\n",
    "The parameters of the estimator/model used to apply these methods are optimized by cross-validated \n",
    "grid-search over a parameter grid.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "estimator = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {'max_depth': np.arange(1,10), \n",
    "              'min_samples_leaf': [1, 2, 5, 7, 10,15,20],\n",
    "              'max_leaf_nodes' : [2, 3, 5, 10],\n",
    "              'min_impurity_decrease': [0.001,0.01,0.1]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(estimator, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "estimator = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Confusion Matrix - decision tree with tuned hyperparameters\n",
    "make_confusion_matrix(estimator,y_test)\n",
    "\n",
    "# Accuracy on train and test\n",
    "print(\"Accuracy on training set : \",estimator.score(X_train, y_train))\n",
    "print(\"Accuracy on test set : \",estimator.score(X_test, y_test))\n",
    "# Recall on train and test\n",
    "get_recall_score(estimator)\n",
    "\n",
    "\n",
    "\n",
    "#visualize the tree\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "tree.plot_tree(estimator,feature_names=feature_names,filled=True,fontsize=9,node_ids=True,class_names=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Text report showing the rules of a decision tree -\n",
    "\n",
    "print(tree.export_text(estimator,feature_names=feature_names,show_weights=True))\n",
    "\n",
    "\n",
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the 'criterion' brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print (pd.DataFrame(estimator.feature_importances_, columns = [\"Imp\"], index = X_train.columns).sort_values(by = 'Imp', ascending = False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################. Post prunning\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Cost Complexity Pruning\n",
    "The DecisionTreeClassifier provides parameters such as min_samples_leaf and max_depth to \n",
    "prevent a tree from overfiting. Cost complexity pruning provides another option to control \n",
    "the size of a tree. In DecisionTreeClassifier, this pruning technique is parameterized by \n",
    "the cost complexity parameter, ccp_alpha. Greater values of ccp_alpha increase the number\n",
    "of nodes pruned. Here we only show the effect of ccp_alpha on regularizing the trees and \n",
    "how to choose a ccp_alpha based on validation scores.\n",
    "\n",
    "Total impurity of leaves vs effective alphas of pruned tree\n",
    "Minimal cost complexity pruning recursively finds the node with the \"weakest link\". \n",
    "The weakest link is characterized by an effective alpha, where the nodes with the smallest \n",
    "effective alpha are pruned first. To get an idea of what values of ccp_alpha could be appropriate,\n",
    "scikit-learn provides DecisionTreeClassifier.cost_complexity_pruning_path that returns the \n",
    "effective alphas and the corresponding total leaf impurities at each step of the pruning process. \n",
    "As alpha increases, more of the tree is pruned, which increases the total impurity of its leaves.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "#check the path\n",
    "pd.DataFrame(path)\n",
    "\n",
    "\n",
    "#goal is to get the alpha as high as possible\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Next, we train a decision tree using the effective alphas. The last value in ccp_alphas is the \n",
    "#alpha value that prunes the whole tree, leaving the tree, clfs[-1], with one node.\n",
    "\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This script is performing pruning on a decision tree model and visualizing the effects of different values \n",
    "of the complexity parameter (alpha) on the number of nodes and the depth of the tree.\n",
    "\n",
    "Here's a breakdown of what each step does:\n",
    "\n",
    "clfs = clfs[:-1] and ccp_alphas = ccp_alphas[:-1]: These lines remove the last element from the clfs and \n",
    "ccp_alphas lists. Each element in the clfs list represents a decision tree model trained with a specific \n",
    "value of the complexity parameter (alpha), while each element in the ccp_alphas list stores the \n",
    "corresponding alpha values.\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]: This line creates a new list called node_counts\n",
    "by iterating over each decision tree model in the clfs list and extracting the number of nodes in each\n",
    "tree using the tree_.node_count attribute.\n",
    "\n",
    "depth = [clf.tree_.max_depth for clf in clfs]: Similarly, this line creates a new list called depth by\n",
    "iterating over each decision tree model and retrieving the maximum depth of each tree using the tree_.\n",
    "max_depth attribute.\n",
    "\n",
    "In summary, the script prunes the decision tree models by removing the last element and then \n",
    "visualizes the relationship between different alpha values and the number of nodes and depth \n",
    "of the decision trees using line graphs in a two-subplot figure. This visualization helps \n",
    "understand how pruning affects the complexity of the decision trees.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1,figsize=(10,7))\n",
    "ax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "#Accuracy vs alpha for training and testing sets\n",
    "#When ccp_alpha is set to zero and keeping the other default parameters of DecisionTreeClassifier, the \n",
    "#tree overfits, leading to a 100% training accuracy and 69% testing accuracy. As alpha increases, more \n",
    "#of the tree is pruned, thus creating a decision tree that generalizes better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################. Random Forrest\n",
    "\n",
    "X = creditData.drop(\"default\" , axis=1)\n",
    "y = creditData.pop(\"default\")\n",
    "\n",
    "\n",
    "#When the target variable you are tryin gto predict is off balance, then you'll want to strafity the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1,stratify=y)\n",
    "\n",
    "\n",
    "#Smote is an optional method to use when your data is imbalanced\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "## Function to create confusion matrix\n",
    "def make_confusion_matrix(model,y_actual,labels=[1, 0]):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "    y_actual : ground truth  \n",
    "    \n",
    "    '''\n",
    "    y_predict = model.predict(X_test)\n",
    "    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[0, 1])\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual - No\",\"Actual - Yes\"]],\n",
    "                  columns = [i for i in ['Predicted - No','Predicted - Yes']])\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "              zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=labels,fmt='')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "    \n",
    "##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\n",
    "def get_metrics_score(model,flag=True):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    # defining an empty list to store train and test results\n",
    "    score_list=[] \n",
    "    \n",
    "    #Predicting on train and tests\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    #Accuracy of the model\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    \n",
    "    #Recall of the model\n",
    "    train_recall = metrics.recall_score(y_train,pred_train)\n",
    "    test_recall = metrics.recall_score(y_test,pred_test)\n",
    "    \n",
    "    #Precision of the model\n",
    "    train_precision = metrics.precision_score(y_train,pred_train)\n",
    "    test_precision = metrics.precision_score(y_test,pred_test)\n",
    "    \n",
    "    score_list.extend((train_acc,test_acc,train_recall,test_recall,train_precision,test_precision))\n",
    "        \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n",
    "        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n",
    "        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n",
    "        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n",
    "        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n",
    "        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n",
    "    \n",
    "    return score_list # returning the list with train and test scores\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Building the model\n",
    "We are going to build 2 ensemble models here - Bagging Classifier and Random Forest Classifier.\n",
    "First, let's build these models with default parameters and then use hyperparameter tuning to \n",
    "optimize the model performance.\n",
    "We will calculate all three metrics - Accuracy, Precision and Recall but the metric of interest \n",
    "here is recall.\n",
    "Recall - It gives the ratio of True positives to Actual positives, so high Recall implies low \n",
    "false negatives, i.e. low chances of predicting a defaulter as non defaulter\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "##Bagging\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "#note you don't need to use bagging with random forrest.  random forrest already has a \n",
    "#from of bagging built in\n",
    "#base_estimator for bagging classifier is a decision tree by default\n",
    "bagging_estimator=BaggingClassifier(random_state=1)\n",
    "bagging_estimator.fit(X_train,y_train)\n",
    "bagging_estimator_score=get_metrics_score(bagging_estimator)\n",
    "make_confusion_matrix(bagging_estimator,y_test)\n",
    "\n",
    "\n",
    "\n",
    "##Random Forrest\n",
    "#Train the random forest classifier\n",
    "rf_estimator=RandomForestClassifier(random_state=1)\n",
    "rf_estimator.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_score=get_metrics_score(rf_estimator)\n",
    "#Random forest will overfit the training data, don't freak out..this is normal\n",
    "#just focus on the test sets\n",
    "\n",
    "\n",
    "make_confusion_matrix(rf_estimator,y_test)\n",
    "\n",
    "\n",
    "\n",
    "##Hypertuning..this is how we can improve the model\n",
    "\n",
    "\"\"\"\n",
    "Detailed definitions\n",
    "\n",
    "class_weights - used to handle class imbalance.  This is only applied to the target variable\n",
    "WEights can be applied to each value in the target variable to inform the algorithm of the importance\n",
    "of each value.  If you have a target variable of yes and no, and the ratio is yes:300, and no:700, \n",
    "then you can apply a weight of 1: .7, 0: .3     To even out how the algorithm focuses on the values\n",
    "\n",
    "base_estimator - you can alter the method of algorithmic predictor you use.  Furth definition as to \n",
    "what you can use and why you would use it is below (1)\n",
    "\n",
    "n_estimators - the number of estimators that are created. the default is 100.  remember, how random forrest\n",
    "works is it makes multiple models, by default it would make 100 models, and basically take the average \n",
    "of all the models.  the more models, the more robust and accurate the prediction.  And it's not impacted\n",
    "by noise in the data. We can use something like 'n_estimators' : [10,20,30,40,50], where the model would be ran 5\n",
    "times with different number of estimators, then the best model will be selected depending on which number\n",
    "or estimators works best\n",
    "\n",
    "max_features - The number of features to consider when looking for the best split.  It applies a proportion value\n",
    "to the feature selection.  You can use 'max_feature': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] \n",
    "to capture every variation of proportion.  why not?\n",
    "\n",
    "max_samples - specifies the proportion from the original dataset to draw from.  so .1 would be 10%,\n",
    "but that would be low and could lead to underfitting, while .9 might be too high and lead to over fitting\n",
    "you could do soemthing like: 'max_samples': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]   \n",
    "\n",
    "oob_score -  out of bag samples.  estimates the performance of a model without the need for a seperate validation\n",
    "dataset.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#########Bagging classifier\n",
    "\n",
    "# Choose the type of classifier. \n",
    "bagging_estimator_tuned = BaggingClassifier(random_state=1)\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {'max_samples': [0.7,0.8,0.9,1], \n",
    "              'max_features': [0.7,0.8,0.9,1],\n",
    "              'n_estimators' : [10,20,30,40,50],\n",
    "             }\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(bagging_estimator_tuned, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "# Set the clf to the best combination of parameters\n",
    "bagging_estimator_tuned = grid_obj.best_estimator_\n",
    "# Fit the best algorithm to the data.\n",
    "bagging_estimator_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "bagging_estimator_tuned_score=get_metrics_score(bagging_estimator_tuned)\n",
    "make_confusion_matrix(bagging_estimator_tuned,y_test)\n",
    "bagging_lr=BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear',random_state=1,max_iter=1000),random_state=1)\n",
    "bagging_lr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "bagging_lr_score=get_metrics_score(bagging_lr)\n",
    "\n",
    "\n",
    "\n",
    "make_confusion_matrix(bagging_lr,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######Random Forrest Classifier\n",
    "\n",
    "# Choose the type of classifier. \n",
    "rf_estimator_tuned = RandomForestClassifier(random_state=1)\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "#you can play around with estimators to see if you can get the best resutls\n",
    "parameters = {\"n_estimators\": [150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1),\n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_estimator_tuned, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_estimator_tuned = grid_obj.best_estimator_\n",
    "# Fit the best algorithm to the data.\n",
    "rf_estimator_tuned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_tuned_score=get_metrics_score(rf_estimator_tuned)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "make_confusion_matrix(rf_estimator_tuned,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###Tuning the model\n",
    "\n",
    "# Choose the type of classifier. \n",
    "rf_estimator_weighted = RandomForestClassifier(random_state=1)\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {\n",
    "    \"class_weight\": [{0: 0.3, 1: 0.7}],\n",
    "    \"n_estimators\": [100,150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1),\n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "}\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_estimator_weighted, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_estimator_weighted = grid_obj.best_estimator_\n",
    "# Fit the best algorithm to the data.\n",
    "rf_estimator_weighted.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_weighted_score=get_metrics_score(rf_estimator_weighted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "make_confusion_matrix(rf_estimator_weighted,y_test)\n",
    "\n",
    "\n",
    "\n",
    "#Check feature importance\n",
    "importances = rf_estimator_weighted.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "feature_names = list(X.columns)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###compare all models\n",
    "\n",
    "# defining list of models\n",
    "models = [bagging_estimator,bagging_estimator_tuned,bagging_lr,rf_estimator,rf_estimator_tuned,\n",
    "          rf_estimator_weighted]\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "# looping through all the models to get the accuracy, precall and precision scores\n",
    "for model in models:\n",
    "    j = get_metrics_score(model,False)\n",
    "    acc_train.append(np.round(j[0],2))\n",
    "    acc_test.append(np.round(j[1],2))\n",
    "    recall_train.append(np.round(j[2],2))\n",
    "    recall_test.append(np.round(j[3],2))\n",
    "    precision_train.append(np.round(j[4],2))\n",
    "    precision_test.append(np.round(j[5],2))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Look at the results in a table\n",
    "\n",
    "comparison_frame = pd.DataFrame({'Model':['Bagging classifier with default parameters','Tuned Bagging Classifier',\n",
    "                                        'Bagging classifier with base_estimator=LR', 'Random Forest with deafult parameters',\n",
    "                                         'Tuned Random Forest Classifier','Random Forest with class_weights'], \n",
    "                                          'Train_Accuracy': acc_train,'Test_Accuracy': acc_test,\n",
    "                                          'Train_Recall':recall_train,'Test_Recall':recall_test,\n",
    "                                          'Train_Precision':precision_train,'Test_Precision':precision_test}) \n",
    "comparison_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17cf8d",
   "metadata": {},
   "source": [
    "\n",
    "## BASE_ESTIMATOR\n",
    "\n",
    "In random forests, you can use a variety of base_estimators as long as they follow the scikit-learn estimator interface. Here are some commonly used base_estimators in random forests:\n",
    "\n",
    "1. DecisionTreeClassifier/DecisionTreeRegressor:\n",
    "   These are the default base_estimators in scikit-learn's RandomForestClassifier and RandomForestRegressor, respectively. They are popular choices because they provide good performance and can handle both classification and regression tasks. Decision trees split the data based on feature values, aiming to minimize impurity (e.g., Gini impurity or entropy) or reduce the mean squared error.\n",
    "\n",
    "2. ExtraTreeClassifier/ExtraTreeRegressor:\n",
    "   ExtraTreeClassifier and ExtraTreeRegressor are similar to DecisionTreeClassifier and DecisionTreeRegressor, respectively. However, they introduce additional randomness during the tree construction process by using random thresholds for feature splits. This randomness can help reduce overfitting and increase the diversity among the trees in the random forest.\n",
    "\n",
    "3. GradientBoostingClassifier/GradientBoostingRegressor:\n",
    "   GradientBoostingClassifier and GradientBoostingRegressor are not typically considered as base_estimators in random forests, but they are boosting algorithms that build an ensemble of weak learners. Boosting focuses on iteratively improving the predictions by giving more weight to the misclassified instances. While not a traditional choice, it is possible to use GradientBoosting as a base_estimator in random forests.\n",
    "\n",
    "4. XGBoost, LightGBM, CatBoost:\n",
    "   These are popular gradient boosting libraries that provide highly optimized implementations of gradient boosting algorithms. While they are not standard base_estimators in scikit-learn's random forests, you can use them as base_estimators by integrating them within the random forest ensemble. These libraries often offer additional features, performance optimizations, and flexibility compared to scikit-learn's default base_estimators.\n",
    "   5. Logistic regression\n",
    "\n",
    "The choice of base_estimator depends on various factors, including the specific problem, dataset characteristics, and desired performance. Here are a few scenarios where you might consider different base_estimators:\n",
    "\n",
    "- DecisionTreeClassifier/DecisionTreeRegressor: These are suitable for most classification and regression tasks and serve as reliable choices with good generalization performance.\n",
    "\n",
    "- ExtraTreeClassifier/ExtraTreeRegressor: If you suspect overfitting in your random forest or want to increase the diversity among the trees, you can use ExtraTreeClassifier/ExtraTreeRegressor due to their additional randomness during tree construction.\n",
    "\n",
    "- GradientBoostingClassifier/GradientBoostingRegressor: If you want to explore a combination of boosting and random forests, you can experiment with using gradient boosting algorithms as base_estimators. This combination might be beneficial in certain cases, but it is less commonly used.\n",
    "\n",
    "- XGBoost, LightGBM, CatBoost: If you require advanced gradient boosting capabilities, improved performance, or specific features offered by these libraries, you can integrate them as base_estimators in your random forest ensemble.\n",
    "\n",
    "-Logistic regression, Post-processing:\n",
    "After training a random forest model, you can use logistic regression as a post-processing step to calibrate the probabilities or fine-tune the predictions. The random forest may provide an initial classification, and logistic regression can be used to refine the probabilities or adjust the decision threshold based on additional considerations or domain-specific requirements.\n",
    "\n",
    "Stacked ensemble:\n",
    "In a stacked ensemble, multiple models are trained on the same dataset, and their predictions are combined using a meta-model. You can include the predictions from a random forest model as one of the inputs along with the predictions from a logistic regression model. The logistic regression model can capture additional patterns or relationships in the data that the random forest may not capture effectively on its own.\n",
    "\n",
    "Feature selection:\n",
    "Logistic regression can be used as a feature selection technique within a random forest framework. You can train a logistic regression model on the features and target variable and utilize the estimated coefficients or feature importance values as a guide to select important features. Then, you can build a random forest model using only the selected features, which can help simplify the model and potentially improve its performance.\n",
    "\n",
    "\n",
    "It's worth noting that the default base_estimators, DecisionTreeClassifier/DecisionTreeRegressor, are reliable choices in most scenarios and often provide satisfactory performance. It's recommended to experiment with different base_estimators and evaluate their impact on your specific problem to determine the most suitable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4eee34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
