{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090e467c",
   "metadata": {},
   "source": [
    "1. NEED TO UNDER STAND THE DIFFERENT DATATYPES FILE FORMATS AND HOW TO PROCESS THEM WHEN BUILDING MODELS\n",
    "\n",
    "2. WHAT LIBRARIES TO USE\n",
    "\n",
    "3. STEPS REQUIRED JUST FOR CNN'S \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9898f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BUILDING THE MODEL WITH HIDDEN LAYERS\n",
    "\n",
    "# Intializing a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding first conv layer with 64 filters and kernel size 3x3 , padding 'same' provides the output size same as the input size\n",
    "# Input_shape denotes input image dimension of images\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=(64, 64, 3)))\n",
    "\n",
    "# Adding max pooling to reduce the size of output of first conv layer\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "# flattening the output of the conv layer after max pooling to make it ready for creating dense connections\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding a fully connected dense layer with 100 neurons    \n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# Adding the output layer with 10 neurons and activation functions as softmax since this is a multi-class classification problem  \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Using SGD Optimizer\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "opt=Adam()\n",
    "# Compile model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69567a51",
   "metadata": {},
   "source": [
    "# TRAIN THE MODEL\n",
    "\n",
    "## Step 1\n",
    "\n",
    "In this step, we import the required libraries, including the ImageDataGenerator from TensorFlow Keras, which is used for data augmentation and preprocessing of images.\n",
    "Define data generators for training and validation data:\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values to the range [0, 1]\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "## Step 2\n",
    "\n",
    "In this step, we create an ImageDataGenerator for training data (train_datagen). This generator performs several data augmentation operations on the training images to increase the diversity of the training dataset. These operations include:\n",
    "Rescaling pixel values to the range [0, 1] by dividing by 255.\n",
    "Horizontal flipping (randomly flipping images horizontally).\n",
    "Vertical flipping (not used in this case).\n",
    "Randomly shifting the height and width of images by a fraction (0.1 in this case).\n",
    "Random rotation of images by up to 20 degrees.\n",
    "Shearing transformation of images.\n",
    "Zooming in/out of images by a factor of 0.1.\n",
    "\n",
    "\n",
    "Define the batch size and target size for your images:\n",
    "\n",
    "\n",
    "## Step 3\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (64, 64)  # Adjust to match your input image size\n",
    "In this step, we set the batch size to 32, which is the number of images processed in each training iteration. You should choose a batch size that fits your hardware capacity.\n",
    "We specify the target size as (64, 64) to match the input image size expected by your model. You should adjust this size to match your specific model's input size.\n",
    "Create data generators for training and validation data:\n",
    "\n",
    "\n",
    "## Step 4\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    target_size=target_size\n",
    ")\n",
    "\n",
    "\n",
    "Here, we create a data generator (train_generator) using ImageDataGenerator.flow_from_directory. This generator reads images from the train_dir directory, rescales them, performs data augmentation, and prepares them for training. We specify the batch size, class mode (set to 'categorical' for multi-class classification), and target size.\n",
    "Repeat the same process for the validation data generator:\n",
    "\n",
    "\n",
    "## Step 5\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    target_size=target_size\n",
    ")\n",
    "\n",
    "\n",
    "Similarly, we create a validation data generator (validation_generator) for the images in the validation_dir directory. This generator is used for evaluating the model during training.\n",
    "Define the number of epochs:\n",
    "\n",
    "\n",
    "\n",
    "## Step 6\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "In this step, we specify the number of training epochs. One epoch represents one complete pass through the entire training dataset.\n",
    "Train the model:\n",
    "\n",
    "\n",
    "## Step 7\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "Finally, we use the model.fit method to train the model. We provide the training and validation data generators as input, specify the number of steps per epoch and epochs, and set verbose to 2 for progress updates.\n",
    "During training, the data generators feed batches of training and validation data to the model, and the model updates its weights based on the loss and optimization algorithm.\n",
    "\n",
    "This script essentially automates the process of loading and preprocessing images, performing data augmentation, and training the model with the generated data batches. It's a common practice in deep learning to use data generators to handle large datasets efficiently and to improve model generalization through data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2105e5",
   "metadata": {},
   "source": [
    "Creating a CNN model containing multiple layers for image processing and dense layer for classification\n",
    "\n",
    "CNN Model layers:\n",
    "\n",
    "Convolutional input layer, 32 feature maps with a size of 3X3 and a * rectifier activation function\n",
    "\n",
    "Batch Normalization\n",
    "\n",
    "Max Pool layer with size 2×2 and a stride of 2\n",
    "\n",
    "Convolutional layer, 64 feature maps with a size of 3X3 and a rectifier activation function.\n",
    "\n",
    "Batch Normalization\n",
    "\n",
    "Max Pool layer with size 2×2 and a stride of 2\n",
    "\n",
    "Convolutional layer, 64 feature maps with a size of 3X3 and a rectifier activation function.\n",
    "\n",
    "Batch Normalization\n",
    "\n",
    "Max Pool layer with size 2×2 and a stride of 2\n",
    "\n",
    "Flatten layer\n",
    "\n",
    "Fully connected or Dense layers (with 512 and 128 neurons) with Relu Act.\n",
    "\n",
    "Dropout layer to reduce overfitting or for regularization\n",
    "\n",
    "O/p layer with Softwax fun. to detect multiple categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bc6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ffb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf63cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d16e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851b646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a749a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
